{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31212304",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as Selenium, BeautifulSoup, requests, and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7330c",
   "metadata": {},
   "source": [
    "# Define Web Scraping Function\n",
    "Define the `extraer_info` function to scrape product titles, descriptions, and image URLs from a given URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14195881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_info(url):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    service = Service()  # Create the service for the driver\n",
    "    driver = webdriver.Chrome(service=service, options=options)  # Start the browser with options\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page and JS to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    driver.quit()\n",
    "\n",
    "    titles = []\n",
    "    descriptions = []\n",
    "    image_urls = []\n",
    "    gif_urls = []\n",
    "\n",
    "    # Extended list of keywords to exclude irrelevant images\n",
    "    blacklist_keywords = [\n",
    "        'logo', 'loggo', 'logotipo', 'favicon', 'icon', 'ico', 'brandmark',\n",
    "        'marca', 'log_', '_logo', 'log-', '-logo', 'logggo', 'watermark',\n",
    "        'paypal', 'sistecredito', 'visa', 'mastercard', 'payment', 'pago',\n",
    "        'credit', 'debit', 'secure', 'checkout', 'cart'\n",
    "    ]\n",
    "\n",
    "    for img in soup.find_all('img'):\n",
    "        src = img.get('src') or img.get('data-src') or img.get('data-image')\n",
    "        if src:\n",
    "            full_url = urljoin(url, src)\n",
    "            full_url_lower = full_url.lower()\n",
    "\n",
    "            # Exclude images containing keywords in the URL\n",
    "            if any(keyword in full_url_lower for keyword in blacklist_keywords):\n",
    "                continue\n",
    "\n",
    "            # Classify images as GIFs or normal images\n",
    "            if full_url_lower.endswith('.gif'):\n",
    "                gif_urls.append(full_url)\n",
    "            else:\n",
    "                image_urls.append(full_url)\n",
    "\n",
    "    # Remove duplicates\n",
    "    image_urls = list(set(image_urls))\n",
    "    gif_urls = list(set(gif_urls))\n",
    "\n",
    "    # Filter images by size (optional, requires requests and Pillow)\n",
    "    filtered_image_urls = []\n",
    "    for img_url in image_urls:\n",
    "        try:\n",
    "            response = requests.get(img_url, stream=True, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                width, height = img.size\n",
    "                # Exclude small images (e.g., icons)\n",
    "                if width > 100 and height > 100:  # Adjust minimum size as needed\n",
    "                    filtered_image_urls.append(img_url)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Add all titles as an additional value\n",
    "    todos_los_titulos = titles\n",
    "\n",
    "    print(\"Product Titles:\", titles)\n",
    "    print(\"Product Descriptions:\", descriptions)\n",
    "    print(\"Filtered Image URLs:\", filtered_image_urls)\n",
    "    print(\"GIF URLs:\", gif_urls)\n",
    "\n",
    "    # Return 5 values\n",
    "    return titles, descriptions, todos_los_titulos, filtered_image_urls, gif_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b445676",
   "metadata": {},
   "source": [
    "# Extract and Filter Image URLs\n",
    "Use the `extraer_info` function to extract and filter image URLs based on size and blacklist keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://dyshopcol.com/products/parches-de-ojos-durazno-bioaqua\"\n",
    "titulo, descripcion, todos_los_titulos, imagenes, gifs = extraer_info(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6d47a",
   "metadata": {},
   "source": [
    "# Display Filtered Images\n",
    "Use matplotlib to display the filtered images retrieved from the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images and URLs\n",
    "for img_url in imagenes:\n",
    "    print(\"URL:\", img_url)\n",
    "    response = requests.get(img_url)\n",
    "    if response.status_code == 200:\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Error loading image from {img_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d73ab",
   "metadata": {},
   "source": [
    "# Test with Example URLs\n",
    "Test the `extraer_info` function with example URLs and print the results, including titles, descriptions, and image URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example URL for testing\n",
    "url = \"https://stanley1913.co/hidratacion/3170-14508-termo-stanley-quick-flip-go.html#/3797-capacidad-36oz1l/4131-color-rose_quartz\"\n",
    "titles, descriptions, image_urls, gif_urls = extraer_info(url)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
